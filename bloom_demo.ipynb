{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install gradio\n",
    "# !pip install transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oanaflores/envs/huggingface/lib/python3.11/site-packages/gradio/inputs.py:27: UserWarning: Usage of gradio.inputs is deprecated, and will not be supported in the future, please import your component from gradio.components\n",
      "  warnings.warn(\n",
      "/Users/oanaflores/envs/huggingface/lib/python3.11/site-packages/gradio/deprecation.py:40: UserWarning: `optional` parameter is deprecated, and it has no effect\n",
      "  warnings.warn(value)\n",
      "/Users/oanaflores/envs/huggingface/lib/python3.11/site-packages/gradio/deprecation.py:40: UserWarning: `numeric` parameter is deprecated, and it has no effect\n",
      "  warnings.warn(value)\n",
      "/Users/oanaflores/envs/huggingface/lib/python3.11/site-packages/gradio/inputs.py:89: UserWarning: Usage of gradio.inputs is deprecated, and will not be supported in the future, please import your component from gradio.components\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'gradio.outputs' has no attribute 'Textarea'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 16\u001b[0m\n\u001b[1;32m     13\u001b[0m num_sequences_slider \u001b[39m=\u001b[39m gr\u001b[39m.\u001b[39minputs\u001b[39m.\u001b[39mSlider(minimum\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, maximum\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m, default\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, step\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, label\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNumber of Sequences\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     14\u001b[0m temperature_slider \u001b[39m=\u001b[39m gr\u001b[39m.\u001b[39minputs\u001b[39m.\u001b[39mSlider(minimum\u001b[39m=\u001b[39m\u001b[39m0.1\u001b[39m, maximum\u001b[39m=\u001b[39m\u001b[39m2.0\u001b[39m, default\u001b[39m=\u001b[39m\u001b[39m1.0\u001b[39m, step\u001b[39m=\u001b[39m\u001b[39m0.1\u001b[39m, label\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mTemperature\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 16\u001b[0m output_label \u001b[39m=\u001b[39m gr\u001b[39m.\u001b[39;49moutputs\u001b[39m.\u001b[39;49mTextarea(\u001b[39mtype\u001b[39m\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mauto\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     18\u001b[0m gr\u001b[39m.\u001b[39mInterface(\n\u001b[1;32m     19\u001b[0m     fn\u001b[39m=\u001b[39mgenerate_text,\n\u001b[1;32m     20\u001b[0m     inputs\u001b[39m=\u001b[39m[input_textbox, max_length_slider, num_sequences_slider, temperature_slider],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     23\u001b[0m     description\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mA demo for the bigscience/bloom-560m model with additional parameter tweaking options.\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     24\u001b[0m )\u001b[39m.\u001b[39mlaunch()\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'gradio.outputs' has no attribute 'Textarea'"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "from transformers import pipeline\n",
    "\n",
    "model_name = \"bigscience/bloom-560m\"\n",
    "nlp_model = pipeline(\"text-generation\", model=model_name, tokenizer=model_name)\n",
    "\n",
    "def generate_text(input_text, max_length, num_sequences, temperature):\n",
    "    generated_text = nlp_model(input_text, max_length=max_length, num_return_sequences=num_sequences, temperature=temperature)\n",
    "    return \"\\n\\n---\\n\\n\".join([sequence[\"generated_text\"] for sequence in generated_text])\n",
    "\n",
    "input_textbox = gr.inputs.Textbox(lines=5, placeholder=\"Enter your text here...\")\n",
    "max_length_slider = gr.inputs.Slider(minimum=10, maximum=200, default=100, step=1, label=\"Max Length\")\n",
    "num_sequences_slider = gr.inputs.Slider(minimum=1, maximum=5, default=1, step=1, label=\"Number of Sequences\")\n",
    "temperature_slider = gr.inputs.Slider(minimum=0.1, maximum=2.0, default=1.0, step=0.1, label=\"Temperature\")\n",
    "\n",
    "output_label = gr.outputs.Textarea(type=\"auto\")\n",
    "\n",
    "gr.Interface(\n",
    "    fn=generate_text,\n",
    "    inputs=[input_textbox, max_length_slider, num_sequences_slider, temperature_slider],\n",
    "    outputs=output_label,\n",
    "    title=\"Bloom-560m Text Generation\",\n",
    "    description=\"A demo for the bigscience/bloom-560m model with additional parameter tweaking options.\",\n",
    ").launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oanaflores/envs/huggingface/lib/python3.11/site-packages/gradio/outputs.py:22: UserWarning: Usage of gradio.outputs is deprecated, and will not be supported in the future, please import your components from gradio.components\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "`type` must be one of \"text\", \"password\", or \"email\".",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 16\u001b[0m\n\u001b[1;32m     13\u001b[0m num_sequences_slider \u001b[39m=\u001b[39m gr\u001b[39m.\u001b[39minputs\u001b[39m.\u001b[39mSlider(minimum\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, maximum\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m, default\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, step\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, label\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNumber of Sequences\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     14\u001b[0m temperature_slider \u001b[39m=\u001b[39m gr\u001b[39m.\u001b[39minputs\u001b[39m.\u001b[39mSlider(minimum\u001b[39m=\u001b[39m\u001b[39m0.1\u001b[39m, maximum\u001b[39m=\u001b[39m\u001b[39m2.0\u001b[39m, default\u001b[39m=\u001b[39m\u001b[39m1.0\u001b[39m, step\u001b[39m=\u001b[39m\u001b[39m0.1\u001b[39m, label\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mTemperature\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 16\u001b[0m output_label \u001b[39m=\u001b[39m gr\u001b[39m.\u001b[39;49moutputs\u001b[39m.\u001b[39;49mTextbox(\u001b[39mtype\u001b[39;49m\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mauto\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m     18\u001b[0m gr\u001b[39m.\u001b[39mInterface(\n\u001b[1;32m     19\u001b[0m     fn\u001b[39m=\u001b[39mgenerate_text,\n\u001b[1;32m     20\u001b[0m     inputs\u001b[39m=\u001b[39m[input_textbox, max_length_slider, num_sequences_slider, temperature_slider],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     23\u001b[0m     description\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mA demo for the bigscience/bloom-560m model with additional parameter tweaking options.\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     24\u001b[0m )\u001b[39m.\u001b[39mlaunch()\n",
      "File \u001b[0;32m~/envs/huggingface/lib/python3.11/site-packages/gradio/outputs.py:25\u001b[0m, in \u001b[0;36mTextbox.__init__\u001b[0;34m(self, type, label)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\n\u001b[1;32m     18\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m     19\u001b[0m     \u001b[39mtype\u001b[39m: \u001b[39mstr\u001b[39m \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     20\u001b[0m     label: Optional[\u001b[39mstr\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m     21\u001b[0m ):\n\u001b[1;32m     22\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m     23\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mUsage of gradio.outputs is deprecated, and will not be supported in the future, please import your components from gradio.components\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     24\u001b[0m     )\n\u001b[0;32m---> 25\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(label\u001b[39m=\u001b[39;49mlabel, \u001b[39mtype\u001b[39;49m\u001b[39m=\u001b[39;49m\u001b[39mtype\u001b[39;49m)\n",
      "File \u001b[0;32m~/envs/huggingface/lib/python3.11/site-packages/gradio/components.py:426\u001b[0m, in \u001b[0;36mTextbox.__init__\u001b[0;34m(self, value, lines, max_lines, placeholder, label, info, every, show_label, interactive, visible, elem_id, elem_classes, type, **kwargs)\u001b[0m\n\u001b[1;32m    409\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    410\u001b[0m \u001b[39mParameters:\u001b[39;00m\n\u001b[1;32m    411\u001b[0m \u001b[39m    value: default text to provide in textarea. If callable, the function will be called whenever the app loads to set the initial value of the component.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    423\u001b[0m \u001b[39m    type: The type of textbox. One of: 'text', 'password', 'email', Default is 'text'.\u001b[39;00m\n\u001b[1;32m    424\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    425\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mtype\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m [\u001b[39m\"\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mpassword\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39memail\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[0;32m--> 426\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39m`type` must be one of \u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\u001b[39mpassword\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m, or \u001b[39m\u001b[39m\"\u001b[39m\u001b[39memail\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    428\u001b[0m \u001b[39m#\u001b[39;00m\n\u001b[1;32m    429\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlines \u001b[39m=\u001b[39m lines\n",
      "\u001b[0;31mValueError\u001b[0m: `type` must be one of \"text\", \"password\", or \"email\"."
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "from transformers import pipeline\n",
    "\n",
    "model_name = \"bigscience/bloom-560m\"\n",
    "nlp_model = pipeline(\"text-generation\", model=model_name, tokenizer=model_name)\n",
    "\n",
    "def generate_text(input_text, max_length, num_sequences, temperature):\n",
    "    generated_text = nlp_model(input_text, max_length=max_length, num_return_sequences=num_sequences, temperature=temperature)\n",
    "    return \"\\n\\n---\\n\\n\".join([sequence[\"generated_text\"] for sequence in generated_text])\n",
    "\n",
    "input_textbox = gr.inputs.Textbox(lines=5, placeholder=\"Enter your text here...\")\n",
    "max_length_slider = gr.inputs.Slider(minimum=10, maximum=200, default=100, step=1, label=\"Max Length\")\n",
    "num_sequences_slider = gr.inputs.Slider(minimum=1, maximum=5, default=1, step=1, label=\"Number of Sequences\")\n",
    "temperature_slider = gr.inputs.Slider(minimum=0.1, maximum=2.0, default=1.0, step=0.1, label=\"Temperature\")\n",
    "\n",
    "output_label = gr.outputs.Textbox(type=\"auto\")\n",
    "\n",
    "gr.Interface(\n",
    "    fn=generate_text,\n",
    "    inputs=[input_textbox, max_length_slider, num_sequences_slider, temperature_slider],\n",
    "    outputs=output_label,\n",
    "    title=\"Bloom-560m Text Generation\",\n",
    "    description=\"A demo for the bigscience/bloom-560m model with additional parameter tweaking options.\",\n",
    ").launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oanaflores/envs/huggingface/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/Users/oanaflores/envs/huggingface/lib/python3.11/site-packages/gradio/inputs.py:27: UserWarning: Usage of gradio.inputs is deprecated, and will not be supported in the future, please import your component from gradio.components\n",
      "  warnings.warn(\n",
      "/Users/oanaflores/envs/huggingface/lib/python3.11/site-packages/gradio/deprecation.py:40: UserWarning: `optional` parameter is deprecated, and it has no effect\n",
      "  warnings.warn(value)\n",
      "/Users/oanaflores/envs/huggingface/lib/python3.11/site-packages/gradio/deprecation.py:40: UserWarning: `numeric` parameter is deprecated, and it has no effect\n",
      "  warnings.warn(value)\n",
      "/Users/oanaflores/envs/huggingface/lib/python3.11/site-packages/gradio/inputs.py:89: UserWarning: Usage of gradio.inputs is deprecated, and will not be supported in the future, please import your component from gradio.components\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'gradio.outputs' has no attribute 'Text'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 16\u001b[0m\n\u001b[1;32m     13\u001b[0m num_sequences_slider \u001b[39m=\u001b[39m gr\u001b[39m.\u001b[39minputs\u001b[39m.\u001b[39mSlider(minimum\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, maximum\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m, default\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, step\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, label\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNumber of Sequences\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     14\u001b[0m temperature_slider \u001b[39m=\u001b[39m gr\u001b[39m.\u001b[39minputs\u001b[39m.\u001b[39mSlider(minimum\u001b[39m=\u001b[39m\u001b[39m0.1\u001b[39m, maximum\u001b[39m=\u001b[39m\u001b[39m2.0\u001b[39m, default\u001b[39m=\u001b[39m\u001b[39m1.0\u001b[39m, step\u001b[39m=\u001b[39m\u001b[39m0.1\u001b[39m, label\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mTemperature\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 16\u001b[0m output_text \u001b[39m=\u001b[39m gr\u001b[39m.\u001b[39;49moutputs\u001b[39m.\u001b[39;49mText(\u001b[39mtype\u001b[39m\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mauto\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     18\u001b[0m gr\u001b[39m.\u001b[39mInterface(\n\u001b[1;32m     19\u001b[0m     fn\u001b[39m=\u001b[39mgenerate_text,\n\u001b[1;32m     20\u001b[0m     inputs\u001b[39m=\u001b[39m[input_textbox, max_length_slider, num_sequences_slider, temperature_slider],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     23\u001b[0m     description\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mA demo for the bigscience/bloom-560m model with additional parameter tweaking options.\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     24\u001b[0m )\u001b[39m.\u001b[39mlaunch()\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'gradio.outputs' has no attribute 'Text'"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "from transformers import pipeline\n",
    "\n",
    "model_name = \"bigscience/bloom-560m\"\n",
    "nlp_model = pipeline(\"text-generation\", model=model_name, tokenizer=model_name)\n",
    "\n",
    "def generate_text(input_text, max_length, num_sequences, temperature):\n",
    "    generated_text = nlp_model(input_text, max_length=max_length, num_return_sequences=num_sequences, temperature=temperature)\n",
    "    return \"\\n\\n---\\n\\n\".join([sequence[\"generated_text\"] for sequence in generated_text])\n",
    "\n",
    "input_textbox = gr.inputs.Textbox(lines=5, placeholder=\"Enter your text here...\")\n",
    "max_length_slider = gr.inputs.Slider(minimum=10, maximum=200, default=100, step=1, label=\"Max Length\")\n",
    "num_sequences_slider = gr.inputs.Slider(minimum=1, maximum=5, default=1, step=1, label=\"Number of Sequences\")\n",
    "temperature_slider = gr.inputs.Slider(minimum=0.1, maximum=2.0, default=1.0, step=0.1, label=\"Temperature\")\n",
    "\n",
    "output_text = gr.outputs.Text(type=\"auto\")\n",
    "\n",
    "gr.Interface(\n",
    "    fn=generate_text,\n",
    "    inputs=[input_textbox, max_length_slider, num_sequences_slider, temperature_slider],\n",
    "    outputs=output_text,\n",
    "    title=\"Bloom-560m Text Generation\",\n",
    "    description=\"A demo for the bigscience/bloom-560m model with additional parameter tweaking options.\",\n",
    ").launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "huggingface",
   "language": "python",
   "name": "huggingface"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c5acb9ffd815cbe564ad2747987d7f39555596647f424f7e7e6361dd2fe2414c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
